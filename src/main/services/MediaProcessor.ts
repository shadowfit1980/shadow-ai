/**
 * ðŸ–¼ï¸ Media Processor
 * 
 * Process images and video:
 * - Sharp, FFmpeg
 */

import { EventEmitter } from 'events';

export class MediaProcessor extends EventEmitter {
    private static instance: MediaProcessor;

    private constructor() { super(); }

    static getInstance(): MediaProcessor {
        if (!MediaProcessor.instance) {
            MediaProcessor.instance = new MediaProcessor();
        }
        return MediaProcessor.instance;
    }

    generateImageProcessing(): string {
        return `// Image Processing with Sharp
// Generated by Shadow AI

import sharp from 'sharp';
import path from 'path';

// Resize image
async function resizeImage(input: Buffer | string, width: number, height?: number) {
    return sharp(input)
        .resize(width, height, {
            fit: 'cover',
            position: 'center'
        })
        .toBuffer();
}

// Create thumbnail
async function createThumbnail(input: Buffer | string, size = 150) {
    return sharp(input)
        .resize(size, size, {
            fit: 'cover',
            position: 'attention' // Smart crop
        })
        .jpeg({ quality: 80 })
        .toBuffer();
}

// Convert format
async function convertFormat(input: Buffer | string, format: 'jpeg' | 'png' | 'webp' | 'avif') {
    const image = sharp(input);
    
    switch (format) {
        case 'jpeg':
            return image.jpeg({ quality: 85, mozjpeg: true }).toBuffer();
        case 'png':
            return image.png({ compressionLevel: 9 }).toBuffer();
        case 'webp':
            return image.webp({ quality: 85 }).toBuffer();
        case 'avif':
            return image.avif({ quality: 65 }).toBuffer();
    }
}

// Optimize for web
async function optimizeForWeb(input: Buffer | string, maxWidth = 1920) {
    const metadata = await sharp(input).metadata();
    
    let pipeline = sharp(input);
    
    // Resize if too large
    if (metadata.width && metadata.width > maxWidth) {
        pipeline = pipeline.resize(maxWidth, null, { withoutEnlargement: true });
    }
    
    // Convert to WebP with optimization
    return pipeline.webp({ quality: 85, effort: 6 }).toBuffer();
}

// Add watermark
async function addWatermark(input: Buffer | string, watermark: Buffer | string, position = 'southeast') {
    const watermarkBuffer = await sharp(watermark)
        .resize(200, 50, { fit: 'inside' })
        .toBuffer();
    
    return sharp(input)
        .composite([{
            input: watermarkBuffer,
            gravity: position as any
        }])
        .toBuffer();
}

// Apply filters
async function applyFilter(input: Buffer | string, filter: 'grayscale' | 'blur' | 'sharpen' | 'sepia') {
    let pipeline = sharp(input);
    
    switch (filter) {
        case 'grayscale':
            pipeline = pipeline.grayscale();
            break;
        case 'blur':
            pipeline = pipeline.blur(5);
            break;
        case 'sharpen':
            pipeline = pipeline.sharpen();
            break;
        case 'sepia':
            pipeline = pipeline.recomb([
                [0.393, 0.769, 0.189],
                [0.349, 0.686, 0.168],
                [0.272, 0.534, 0.131]
            ]);
            break;
    }
    
    return pipeline.toBuffer();
}

// Get image metadata
async function getMetadata(input: Buffer | string) {
    const metadata = await sharp(input).metadata();
    return {
        width: metadata.width,
        height: metadata.height,
        format: metadata.format,
        size: metadata.size,
        hasAlpha: metadata.hasAlpha,
        orientation: metadata.orientation
    };
}

// Generate responsive images
async function generateResponsiveImages(input: Buffer | string, outputDir: string, filename: string) {
    const sizes = [320, 640, 960, 1280, 1920];
    const results = [];
    
    for (const width of sizes) {
        const outputPath = path.join(outputDir, \`\${filename}-\${width}w.webp\`);
        await sharp(input)
            .resize(width, null, { withoutEnlargement: true })
            .webp({ quality: 85 })
            .toFile(outputPath);
        results.push({ width, path: outputPath });
    }
    
    return results;
}

// Extract dominant color
async function getDominantColor(input: Buffer | string) {
    const { dominant } = await sharp(input)
        .resize(10, 10, { fit: 'cover' })
        .stats();
    
    return {
        r: Math.round(dominant.r),
        g: Math.round(dominant.g),
        b: Math.round(dominant.b),
        hex: \`#\${[dominant.r, dominant.g, dominant.b].map(c => Math.round(c).toString(16).padStart(2, '0')).join('')}\`
    };
}

export { resizeImage, createThumbnail, convertFormat, optimizeForWeb, addWatermark, applyFilter, getMetadata, generateResponsiveImages, getDominantColor };
`;
    }

    generateVideoProcessing(): string {
        return `// Video Processing with FFmpeg
// Generated by Shadow AI

import ffmpeg from 'fluent-ffmpeg';
import { path as ffmpegPath } from '@ffmpeg-installer/ffmpeg';
import { path as ffprobePath } from '@ffprobe-installer/ffprobe';

ffmpeg.setFfmpegPath(ffmpegPath);
ffmpeg.setFfprobePath(ffprobePath);

// Get video metadata
async function getVideoInfo(inputPath: string): Promise<any> {
    return new Promise((resolve, reject) => {
        ffmpeg.ffprobe(inputPath, (err, metadata) => {
            if (err) reject(err);
            else resolve({
                duration: metadata.format.duration,
                size: metadata.format.size,
                bitrate: metadata.format.bit_rate,
                width: metadata.streams[0]?.width,
                height: metadata.streams[0]?.height,
                fps: eval(metadata.streams[0]?.r_frame_rate || '0'),
                codec: metadata.streams[0]?.codec_name
            });
        });
    });
}

// Generate thumbnail
async function generateThumbnail(inputPath: string, outputPath: string, timestamp = '00:00:01') {
    return new Promise((resolve, reject) => {
        ffmpeg(inputPath)
            .screenshots({
                timestamps: [timestamp],
                filename: outputPath,
                size: '640x360'
            })
            .on('end', resolve)
            .on('error', reject);
    });
}

// Generate video thumbnails sprite
async function generateThumbnailSprite(inputPath: string, outputDir: string) {
    return new Promise((resolve, reject) => {
        ffmpeg(inputPath)
            .outputOptions([
                '-vf', 'fps=1/10,scale=160:90,tile=10x10',
                '-frames:v', '1'
            ])
            .output(\`\${outputDir}/sprite.jpg\`)
            .on('end', resolve)
            .on('error', reject)
            .run();
    });
}

// Transcode video
async function transcodeVideo(inputPath: string, outputPath: string, options: { 
    resolution?: '720p' | '1080p' | '4k',
    format?: 'mp4' | 'webm',
    bitrate?: string 
} = {}) {
    const resolutionMap = { '720p': '1280x720', '1080p': '1920x1080', '4k': '3840x2160' };
    
    return new Promise((resolve, reject) => {
        let command = ffmpeg(inputPath);
        
        if (options.resolution) {
            command = command.size(resolutionMap[options.resolution]);
        }
        
        if (options.format === 'webm') {
            command = command.videoCodec('libvpx-vp9').audioCodec('libopus');
        } else {
            command = command.videoCodec('libx264').audioCodec('aac');
        }
        
        if (options.bitrate) {
            command = command.videoBitrate(options.bitrate);
        }
        
        command
            .output(outputPath)
            .on('progress', (progress) => console.log(\`Processing: \${progress.percent?.toFixed(1)}%\`))
            .on('end', resolve)
            .on('error', reject)
            .run();
    });
}

// Extract audio
async function extractAudio(inputPath: string, outputPath: string) {
    return new Promise((resolve, reject) => {
        ffmpeg(inputPath)
            .noVideo()
            .audioCodec('libmp3lame')
            .audioBitrate('192k')
            .output(outputPath)
            .on('end', resolve)
            .on('error', reject)
            .run();
    });
}

// Create GIF from video
async function createGif(inputPath: string, outputPath: string, options: { start?: number, duration?: number, fps?: number, width?: number } = {}) {
    const { start = 0, duration = 5, fps = 10, width = 480 } = options;
    
    return new Promise((resolve, reject) => {
        ffmpeg(inputPath)
            .setStartTime(start)
            .setDuration(duration)
            .outputOptions([
                '-vf', \`fps=\${fps},scale=\${width}:-1:flags=lanczos,split[s0][s1];[s0]palettegen[p];[s1][p]paletteuse\`
            ])
            .output(outputPath)
            .on('end', resolve)
            .on('error', reject)
            .run();
    });
}

// Compress video
async function compressVideo(inputPath: string, outputPath: string) {
    return new Promise((resolve, reject) => {
        ffmpeg(inputPath)
            .videoCodec('libx264')
            .outputOptions(['-crf', '28', '-preset', 'slow'])
            .output(outputPath)
            .on('end', resolve)
            .on('error', reject)
            .run();
    });
}

export { getVideoInfo, generateThumbnail, generateThumbnailSprite, transcodeVideo, extractAudio, createGif, compressVideo };
`;
    }
}

export const mediaProcessor = MediaProcessor.getInstance();
