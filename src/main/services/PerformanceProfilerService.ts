/**
 * ðŸ“Š PerformanceProfilerService
 * 
 * Code performance profiling:
 * - Bottlenecks, memory, CPU
 */

import { EventEmitter } from 'events';

export class PerformanceProfilerService extends EventEmitter {
    private static instance: PerformanceProfilerService;
    private constructor() { super(); }
    static getInstance(): PerformanceProfilerService {
        if (!PerformanceProfilerService.instance) {
            PerformanceProfilerService.instance = new PerformanceProfilerService();
        }
        return PerformanceProfilerService.instance;
    }

    generate(): string {
        return `// Performance Profiler Service - Bottlenecks, memory
// Generated by Shadow AI

import v8 from 'v8';

class PerformanceProfiler {
    private samples: Map<string, number[]> = new Map();
    
    startProfiling(name: string): () => number {
        const start = performance.now();
        
        return () => {
            const duration = performance.now() - start;
            if (!this.samples.has(name)) this.samples.set(name, []);
            this.samples.get(name)!.push(duration);
            return duration;
        };
    }
    
    getMemoryUsage(): MemoryInfo {
        const heapStats = v8.getHeapStatistics();
        const memUsage = process.memoryUsage();
        
        return {
            heapUsed: memUsage.heapUsed,
            heapTotal: memUsage.heapTotal,
            external: memUsage.external,
            rss: memUsage.rss,
            heapSizeLimit: heapStats.heap_size_limit,
            usedPercentage: (memUsage.heapUsed / heapStats.heap_size_limit) * 100
        };
    }
    
    async profileFunction<T>(name: string, fn: () => Promise<T>): Promise<{ result: T; profile: FunctionProfile }> {
        const memBefore = this.getMemoryUsage();
        const stop = this.startProfiling(name);
        
        const result = await fn();
        
        const duration = stop();
        const memAfter = this.getMemoryUsage();
        
        return {
            result,
            profile: {
                name,
                duration,
                memoryDelta: memAfter.heapUsed - memBefore.heapUsed,
                timestamp: Date.now()
            }
        };
    }
    
    getStats(name: string): ProfileStats | null {
        const samples = this.samples.get(name);
        if (!samples || samples.length === 0) return null;
        
        const sorted = [...samples].sort((a, b) => a - b);
        
        return {
            name,
            count: samples.length,
            min: Math.min(...samples),
            max: Math.max(...samples),
            avg: samples.reduce((a, b) => a + b, 0) / samples.length,
            p50: sorted[Math.floor(sorted.length * 0.5)],
            p95: sorted[Math.floor(sorted.length * 0.95)],
            p99: sorted[Math.floor(sorted.length * 0.99)]
        };
    }
    
    getAllStats(): ProfileStats[] {
        return Array.from(this.samples.keys()).map(name => this.getStats(name)!).filter(Boolean);
    }
    
    clear(): void {
        this.samples.clear();
    }
    
    async analyzeBottlenecks(code: string): Promise<BottleneckAnalysis> {
        const response = await llm.chat([{
            role: 'system',
            content: \`Analyze this code for performance issues. Identify:
            - Time complexity issues
            - Memory leaks
            - Unnecessary computations
            - Blocking operations
            Return JSON: { issues: [{ line, severity, description, suggestion }] }\`
        }, {
            role: 'user',
            content: code
        }]);
        
        return JSON.parse(response.content);
    }
}

export { PerformanceProfiler };
`;
    }
}

export const performanceProfilerService = PerformanceProfilerService.getInstance();
