/**
 * ‚öñÔ∏è ShadowJudgeService
 * 
 * LLM-as-judge self-evaluation:
 * - Quality scoring, rubrics, auto-improvement
 */

import { EventEmitter } from 'events';

export class ShadowJudgeService extends EventEmitter {
    private static instance: ShadowJudgeService;
    private constructor() { super(); }
    static getInstance(): ShadowJudgeService {
        if (!ShadowJudgeService.instance) {
            ShadowJudgeService.instance = new ShadowJudgeService();
        }
        return ShadowJudgeService.instance;
    }

    generate(): string {
        return `// Shadow Judge Service - LLM-as-judge self-evaluation
// Generated by Shadow AI

class ShadowJudge {
    private rubrics: Record<string, Rubric> = {
        maintainability: {
            name: 'Maintainability',
            criteria: [
                'Clear variable/function naming',
                'Single responsibility principle',
                'DRY (Don\'t Repeat Yourself)',
                'Consistent code style',
                'Adequate documentation'
            ],
            weight: 0.25
        },
        performance: {
            name: 'Performance',
            criteria: [
                'Optimal time complexity',
                'Memory efficiency',
                'No unnecessary computations',
                'Proper async/await usage',
                'Caching where appropriate'
            ],
            weight: 0.25
        },
        security: {
            name: 'Security',
            criteria: [
                'Input validation',
                'No hardcoded secrets',
                'Proper authentication checks',
                'SQL injection prevention',
                'XSS protection'
            ],
            weight: 0.25
        },
        elegance: {
            name: 'Elegance',
            criteria: [
                'Idiomatic patterns',
                'Minimal abstraction leaks',
                'Testability',
                'Error handling',
                'Modern best practices'
            ],
            weight: 0.25
        }
    };
    
    // Judge generated code
    async judge(code: string, context?: string): Promise<JudgementResult> {
        const scores: Record<string, CategoryScore> = {};
        
        for (const [key, rubric] of Object.entries(this.rubrics)) {
            const score = await this.evaluateCategory(code, rubric, context);
            scores[key] = score;
        }
        
        const totalScore = Object.entries(scores).reduce(
            (sum, [key, cat]) => sum + cat.score * this.rubrics[key].weight * 100,
            0
        );
        
        return {
            totalScore: Math.round(totalScore),
            categories: scores,
            improvements: await this.suggestImprovements(code, scores),
            verdict: this.getVerdict(totalScore)
        };
    }
    
    private async evaluateCategory(code: string, rubric: Rubric, context?: string): Promise<CategoryScore> {
        const response = await llm.chat([{
            role: 'system',
            content: \`You are a code quality judge. Evaluate this code on "\${rubric.name}" using these criteria:
\${rubric.criteria.map((c, i) => \`\${i + 1}. \${c}\`).join('\\n')}

Return JSON: { score: 0-1, strengths: string[], weaknesses: string[], details: string }\`
        }, {
            role: 'user',
            content: \`Code:\n\${code}\${context ? \`\\n\\nContext: \${context}\` : ''}\`
        }]);
        
        return JSON.parse(response.content);
    }
    
    private async suggestImprovements(code: string, scores: Record<string, CategoryScore>): Promise<Improvement[]> {
        const weakCategories = Object.entries(scores)
            .filter(([_, cat]) => cat.score < 0.7)
            .map(([key, cat]) => ({ category: key, weaknesses: cat.weaknesses }));
        
        if (weakCategories.length === 0) return [];
        
        const response = await llm.chat([{
            role: 'system',
            content: 'Suggest specific code improvements. Return JSON array: [{ description, before, after, priority }]'
        }, {
            role: 'user',
            content: \`Code:\n\${code}\\n\\nWeaknesses:\n\${JSON.stringify(weakCategories)}\`
        }]);
        
        return JSON.parse(response.content);
    }
    
    private getVerdict(score: number): string {
        if (score >= 90) return 'üèÜ Exceptional - Ready for production';
        if (score >= 80) return '‚úÖ Good - Minor improvements suggested';
        if (score >= 70) return '‚ö†Ô∏è Acceptable - Review recommended';
        if (score >= 50) return 'üîß Needs Work - Significant issues';
        return '‚ùå Poor - Major refactoring required';
    }
    
    // Auto-improve code based on judgement
    async autoImprove(code: string): Promise<{ improved: string; changes: string[] }> {
        const judgement = await this.judge(code);
        
        if (judgement.totalScore >= 90) {
            return { improved: code, changes: [] };
        }
        
        const response = await llm.chat([{
            role: 'system',
            content: 'Improve this code based on the suggestions. Return only the improved code.'
        }, {
            role: 'user',
            content: \`Code:\n\${code}\\n\\nImprovements:\n\${JSON.stringify(judgement.improvements)}\`
        }]);
        
        return {
            improved: response.content,
            changes: judgement.improvements.map(i => i.description)
        };
    }
    
    // Compare two implementations
    async compare(codeA: string, codeB: string): Promise<ComparisonResult> {
        const [judgeA, judgeB] = await Promise.all([
            this.judge(codeA),
            this.judge(codeB)
        ]);
        
        return {
            winner: judgeA.totalScore >= judgeB.totalScore ? 'A' : 'B',
            scoreA: judgeA.totalScore,
            scoreB: judgeB.totalScore,
            analysis: await this.analyzeComparison(codeA, codeB, judgeA, judgeB)
        };
    }
}

export { ShadowJudge };
`;
    }
}

export const shadowJudgeService = ShadowJudgeService.getInstance();
